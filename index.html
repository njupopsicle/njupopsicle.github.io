<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="stylesheet" href="nju.css" type="text/css" />
<title>Popsicle's Homepage</title>
</head>
<body>
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?f85ae40b6d54f8f7becb3b0be41d4515";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="image-container">
    <img src="./projects/1200px-NJU.svg.png" width="90px" height="112px" alt="NJU">
</div>
<div class="menu-item"><a href="index.html" class="current">Homepage</a></div>
<div class="menu-item"><a href="pub.html">Publications</a></div>
<div class="menu-item"><a href="group.html">Members</a></div>
<div class="menu-item"><a href="service.html">Services</a></div>
<div class="menu-item"><a href="award.html">Awards</a></div>
<!-- <div class="menu-item"><a href="join.html">Join&nbsp;us</a></div> -->
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Popsicle's Homepage</h1>
</div>
<table class="imgtable"><tr><td>
<img src="./projects/lengtoo.jpg" alt="Popsicle's profile picture" width="444px" height="380px" />&nbsp;</td>
<td align="left"><p><b><a href="https://njusz.nju.edu.cn/b0/7a/c52366a635002/page.htm">Popsicle</a></b>
</p>
<p><b>Associate Professor (PhD Advisor)</b>
</p>
<p><a href="https://www.nju.edu.cn/main.htm" target=&ldquo;blank&rdquo;>Nanjing University (Xianlin Campus)</a>
</p>
<p>163 Xianlin Avenue, Nanjing, P.R. China
</p>
<p><b>Email:</b> jskou(at)smail.nju.edu.cn; jskou(at)qq.com
</p>
<p><!--<a href="https://scholar.google.com/citations?user=NKaiUasAAAAJ&hl=en" target=&ldquo;blank&rdquo;>Google Scholar</a> | -->
  <a href="https://github.com/njupopsicle/" target=&ldquo;blank&rdquo;>Github</a> |
  <!-- <a href="https://www.scopus.com/authid/detail.uri?authorId=56437886200">Scopus</a> -->
</p>
</td></tr></table>

<div class="infoblock">
<div class="blocktitle"></div>
<div class="blockcontent">
<p><b><font color=red>Looking for self-motivated graduate students (both Ph.D. and master) working with me. For prospective students, please send me your resume and transcript. 
</font></b></p>
<p><b><font color=red><span lang="zh-CN" xml:lang="zh-CN"> Opening positions <b><a href="https://jessezhang92.github.io/data/admission.pdf">(招生简介)</a></b>: 本人2024年秋季入学博士人选已确定，还有1个硕士名额，1个科研助理名额（需要应届毕业生身份，满足条件的且感兴趣的欢迎邮件联系）。同时欢迎对生成式视觉技术感兴趣，想要在顶会顶刊发表论文的同学找我科研合作，谢谢！</span>
</font></b></p>
</div></div>
<h2>Biography</h2>
<p>I am currently an Associate Professor at School of Intelligence Science and Technology, Nanjing University (Suzhou Campus). 
  Previously, I was a Principal Researcher and Team Lead at Tencent Youtu Lab, where I spent more than 6 wonderful years, leading two teams developing novel vision algorithms that are applied in several products, e.g., Virtual Background feature in Tencent Meeting, High-fidelity face generation APIs in Tencent Cloud and Talking Face Generation for digital human product. Also, our team conducted cutting-edge research works that are published in top-tier AI conferences.
</p>
<p>I got my Ph.D. degree from the Department of Computer Science and Engineering, Nanjing University of Science & Technology (NUST) in 2017, and my advisor is Prof. <a href="http://www.patternrecognition.cn/~jian/">Jian Yang</a>. In 2016, I spent 6 wonderful months as a visiting student at Prof. <a href="http://www.cse.msu.edu/~liuxm/">Xiaoming Liu</a>'s lab in Michigan State University. 
</p>
<p>My research interests include Frontier Generative AI research and applications based on advanced large vision and language models. Specifically, I work on </p>
<ul>
<li><p>Human-centric text-to-image editing and generation </p></li>
<li><p>Multi-modal understanding (vision and language) & generation:
  <a href="https://arxiv.org/pdf/2303.14700.pdf"; style="color: #EE7F2D;"> <b>ImAM (ICCV'23)</b></a>
  <a href="https://arxiv.org/pdf/2305.02572.pdf"; style="color: #EE7F2D;"> <b>EmotionalTalkingFace (CVPR'23)</b></a>
</p></li>
<li><p>High-fidelity image/video restoration:  
  <a href="https://arxiv.org/pdf/2302.03406.pdf"; style="color: #EE7F2D;"> <b>CRI (AAAI'23)</b></a>; 
  <a href="https://drive.google.com/file/d/19jhYLzOsCpDsG1ntvg6rfV-4NzHPKEwW/view"; style="color: #EE7F2D;"> <b>Colorformer (ECCV'22)</b></a>; 
  <a href="https://drive.google.com/file/d/1oj4uCqu7E2913JKLohu7nZsj5SvECCdq/view"; style="color: #EE7F2D;"> <b>IFRNet (CVPR'22)</b></a>; 
  <a href="https://arxiv.org/pdf/2110.12151.pdf"; style="color: #EE7F2D;"> <b>S2K (NeurIPS'22)</b></a>;
  <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Learning_To_Restore_Hazy_Video_A_New_Real-World_Dataset_and_CVPR_2021_paper.pdf"; style="color: #EE7F2D;"> <b>VideoDehaze (CVPR'21)</b></a>;
  <a href="https://arxiv.org/pdf/2012.10102.pdf"; style="color: #EE7F2D;"> <b>FCA (AAAI'21)</b></a>;
  <a href="http://cvlab.cse.msu.edu/pdfs/Image_Restoration%20using_Persistent_Memory_Network.pdf"; style="color: #EE7F2D;"> <b>MemNet (ICCV'17)</b></a>;
  <a href="http://cvlab.cse.msu.edu/pdfs/Tai_Yang_Liu_CVPR2017.pdf"; style="color: #EE7F2D;"> <b>DRRN (CVPR'17)</b></a>
</p></li>
<li><p>Virtual digital human (2D and 3D): 
  <a href="https://drive.google.com/file/d/1r8jcuDpYAnwRM9HOaVJr9BgvRf9L0Vks/view?pli=1"; style="color: #EE7F2D;"> <b>NPF (CVPR'23)</b></a>; 
  <a href="https://arxiv.org/pdf/2106.09965.pdf"; style="color: #EE7F2D;"> <b>SGPN (CVPR'22)</b></a>; 
  <a href="https://arxiv.org/pdf/2106.09965.pdf"; style="color: #EE7F2D;"> <b>Uniface (ECCV'22)</b></a>; 
  <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136760281.pdf"; style="color: #EE7F2D;"> <b>Styleface (ECCV'22)</b></a>; 
  <a href="https://www.ijcai.org/proceedings/2022/0244.pdf"; style="color: #EE7F2D;"> <b>HifiHead (IJCAI'22)</b></a>; 
  <a href="https://arxiv.org/pdf/2106.09965.pdf"; style="color: #EE7F2D;"> <b>HifiFace (IJCAI'21)</b></a>
</p></li>
<li><p>Image/video perception and understanding:  
  <a href="https://arxiv.org/pdf/2203.11624.pdf"; style="color: #EE7F2D;"> <b>HitNet (AAAI'23)</b></a>; 
  <a href="https://arxiv.org/pdf/2207.06654.pdf"; style="color: #EE7F2D;"> <b>ProCA (ECCV'22)</b></a>; 
  <a href="https://drive.google.com/file/d/1aCz2WOuxa3ppYkb2i43i6_WamA9drLU9/view"; style="color: #EE7F2D;"> <b>LCTR (AAAI'22)</b></a>; 
  <a href="https://drive.google.com/file/d/1nbmqKc7fDM3zrGFLDEghnhWw_Uu8yuQ6/view"; style="color: #EE7F2D;"> <b>Curricularface (CVPR'20)</b></a>; 
  <a href="https://arxiv.org/pdf/2007.14557.pdf"; style="color: #EE7F2D;"> <b>ChainedTracker (ECCV'20)</b></a>; 
  <a href="https://drive.google.com/file/d/1DuhcD4Thwv8E3kcLZIOQTeo8qaGDq9PB/view"; style="color: #EE7F2D;"> <b>DSFD (CVPR'19)</b></a>
</ul>
  
<h2>Past Projects on Generative AI</h2>
<ul>
  <li><p style="text-align:left">High fidelity face generation: <a href="https://cloud.tencent.com/act/pro/facefusion_video?from=20218"; style="color: #EE7F2D;"><span lang="zh-CN" xml:lang="zh-CN"><b>Video face fusion (腾讯云-视频人脸融合)</b></span></a> </p></li>
</ul>
  
<h2>News</h2>
<ul>
  <li><p style="text-align:left">10/2023 – 2022 World's Top 2% Scientists by Stanford University (<a href="https://jokergoooo.shinyapps.io/top2pct_scientists/_w_08464be4/#"; style="color: #EE7F2D;"> <b>Ranked 5th in Tencent</b></a>) </p></li> 
  <li><p style="text-align:left">09/2023 – 1 paper (<a href="https://arxiv.org/pdf/2309.03508.pdf"; style="color: #EE7F2D;"> <b>WaveletVFI</b></a>) accepted by IEEE Transactions on Image Processing 2023 </p></li>
  <li><p style="text-align:left">08/2023 – I joined Nanjing University (Suzhou Campus) </p></li>
</ul>

<br>
     <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=7NBHDtDocG-5aHJwvsVx0gDJQvoE-W7fjROXXVCHk4o&cl=ffffff&w=a"></script>
<!-- <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=faf9f9&w=300&t=tt&d=hvoHWGKZcyFl6zhd6aLhpusD9f4jQY_gzPG8UfsmW0I&co=1285d6'></script> -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.4/jquery.min.js" integrity="sha3848gBf6Y4YYq7Jx97PIqmTwLPin4hxIzQw5aDmUg/DDhul9fFpbbLcLh3nTIIDJKhx" crossorigin="anonymous"></script>
<script src="script.js"></script><table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
<div id="footer">
<div id="footer-text">
Last modified in July 2023, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
  
</td>
</tr>
</table>
</body>
</html>
